文本生成

Gemini API 可以利用 Gemini 模型，根据各种输入（包括文本、图片、视频和音频）生成文本输出。

下面是一个接受单个文本输入的基本示例：

Python
JavaScript
Go
REST
Apps 脚本

from google import genai

client = genai.Client()

response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents="How does AI work?"
)
print(response.text)

使用 Gemini 2.5 进行思考
2.5 Flash 和 Pro 模型默认启用了“思考”功能，以提升质量，这可能会导致运行时间延长并增加令牌用量。

使用 2.5 Flash 时，您可以通过将思考预算设置为零来停用思考功能。

如需了解详情，请参阅思考指南。

Python
JavaScript
Go
REST
Apps 脚本

from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents="How does AI work?",
    config=types.GenerateContentConfig(
        thinking_config=types.ThinkingConfig(thinking_budget=0) # Disables thinking
    ),
)
print(response.text)
系统说明和其他配置
您可以使用系统指令来引导 Gemini 模型的行为。为此，请传递 GenerateContentConfig 对象。

Python
JavaScript
Go
REST
Apps 脚本

from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_content(
    model="gemini-2.5-flash",
    config=types.GenerateContentConfig(
        system_instruction="You are a cat. Your name is Neko."),
    contents="Hello there"
)

print(response.text)
借助 GenerateContentConfig 对象，您还可以替换默认生成参数，例如温度。

Python
JavaScript
Go
REST
Apps 脚本

from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents=["Explain how AI works"],
    config=types.GenerateContentConfig(
        temperature=0.1
    )
)
print(response.text)
如需查看可配置参数及其说明的完整列表，请参阅 API 参考文档中的 GenerateContentConfig。

多模态输入
Gemini API 支持多模态输入，可让您将文本与媒体文件组合使用。以下示例演示了如何提供图片：

Python
JavaScript
Go
REST
Apps 脚本

from PIL import Image
from google import genai

client = genai.Client()

image = Image.open("/path/to/organ.png")
response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents=[image, "Tell me about this instrument"]
)
print(response.text)
如需了解提供图片的其他方法和更高级的图片处理，请参阅我们的图片理解指南。该 API 还支持文档、视频和音频输入和理解。

流式响应
默认情况下，模型仅在整个生成过程完成后才会返回回答。

为了实现更流畅的互动，请使用流式传输在 GenerateContentResponse 实例生成时逐步接收这些实例。

Python
JavaScript
Go
REST
Apps 脚本

from google import genai

client = genai.Client()

response = client.models.generate_content_stream(
    model="gemini-2.5-flash",
    contents=["Explain how AI works"]
)
for chunk in response:
    print(chunk.text, end="")
多轮对话（聊天）
我们的 SDK 提供了将多轮提示和回复收集到聊天中的功能，让您可以轻松跟踪对话记录。

注意 ：聊天功能仅在 SDK 中实现。在后台，它仍会使用 generateContent API。对于多轮对话，系统会在每次后续对话时将完整对话记录发送给模型。
Python
JavaScript
Go
REST
Apps 脚本

from google import genai

client = genai.Client()
chat = client.chats.create(model="gemini-2.5-flash")

response = chat.send_message("I have 2 dogs in my house.")
print(response.text)

response = chat.send_message("How many paws are in my house?")
print(response.text)

for message in chat.get_history():
    print(f'role - {message.role}',end=": ")
    print(message.parts[0].text)
流式传输还可用于多轮对话。

Python
JavaScript
Go
REST
Apps 脚本

from google import genai

client = genai.Client()
chat = client.chats.create(model="gemini-2.5-flash")

response = chat.send_message_stream("I have 2 dogs in my house.")
for chunk in response:
    print(chunk.text, end="")

response = chat.send_message_stream("How many paws are in my house?")
for chunk in response:
    print(chunk.text, end="")

for message in chat.get_history():
    print(f'role - {message.role}', end=": ")
    print(message.parts[0].text)
支持的模型
Gemini 系列中的所有模型都支持文本生成。如需详细了解这些模型及其功能，请访问模型页面。

最佳做法
提示技巧
对于基本文本生成，通常只需零样本提示即可，而无需示例、系统说明或特定格式。

如需获得更贴合需求的输出，请执行以下操作：

使用系统指令来引导模型。
提供一些示例输入和输出来引导模型。这通常称为少样本提示。
如需更多提示，请参阅我们的提示工程指南。

结构化输出
在某些情况下，您可能需要结构化输出，例如 JSON。如需了解具体方法，请参阅我们的结构化输出指南。

后续步骤
试用 Gemini API 使用入门 Colab。
探索 Gemini 的图片、视频、音频和文档理解功能。
了解多模态文件提示策略。